#!/usr/bin/env bash

#
# To run the demo, just run `sh/full-tag-site-demo` from the root of the
# repository.
#

THREADS=16
FIRST_PAGE=1
# Use --last-page to pick a different range.

USE_LOCAL=0
USE_CDN=0
RUN_TESTS=0
CHECK_LIMITS=1
REQ_LAST_PAGE=0
MACHINE_DIR=$(realpath .fulltag-demo)
MACHINE_ARGS=()

usage ()
{
    echo "Usage: ./full-tag-site-demo [ -d | --demosrc SRCDIR ]
                            [ --use-local | --use-cdn ]
                            [ --ci ]
                            [ --no-check-limits ]
                            [ --last-page NUM ]
                            [ --machine-dir MACHINEDIR ]
                            [ -p | --profile-output PROF_FILE ]
                            [ -P | --profile-laws ]

    full-tag-site-demo will try to download a small 600 json file demo if
    '-d' is unset.

    You can download a larger 70GB dataset that contains a million images
    by downloading this torrent:

    magnet:?xt=urn:btih:c2f603468767fc098ddb8f0d560688caa6690304&dn=safe-score-gte-37.tar.gz&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce"
    exit 2
}

PARSED_ARGUMENTS=$(
    getopt -a -n alphabet \
        -o d:p:P \
        --long demosrc:,machine-dir:,profile-output:,last-page:,no-check-limits,ci,profile-laws,use-local,use-cdn,help \
        -- "$@"
)
VALID_ARGUMENTS=$?
if [ "$VALID_ARGUMENTS" != "0" ]; then
  usage
fi

#echo "PARSED_ARGUMENTS is $PARSED_ARGUMENTS"
eval set -- "$PARSED_ARGUMENTS"
while :
do
  case "$1" in
    -d | --demosrc)        DEMOSRC="$2"             ; shift 2 ;;
    --use-local)           USE_LOCAL=1              ; shift   ;;
    --use-cdn)             USE_CDN=1                ; shift   ;;
    --last-page)           REQ_LAST_PAGE="$2"       ; shift 2 ;;
    --machine-dir)         MACHINE_DIR="$2"         ; shift 2 ;;
    -p | --profile-output) MACHINE_ARGS+=("-p" "$2"); shift 2 ;;
    -P | --profile-laws)   MACHINE_ARGS+=("-P")     ; shift   ;;
    --no-check-limits)     CHECK_LIMITS=0           ; shift   ;;

    --ci)
        RUN_TESTS=1
        CHECK_LIMITS=0
        DEMOSRC=testdata/fulltag
        shift 1
        ;;

    # Don't "error" on help.
    --help) usage ;;

    # -- means the end of the arguments; drop this, and break out of the while loop
    --) shift; break ;;

    # If invalid options were passed, then getopt should have reported an error,
    # which we checked as VALID_ARGUMENTS when getopt was called...
    *) echo "Unexpected option: $1 - this should not happen."
       usage ;;
  esac
done

# Both curl and pallas consume a ton of file descriptors and mmap segments, in
# the current demo design. We must check that we have enough fds for all files,
# and that we have a high enough max_map_count.

# Set a minimum required limit
MIN_LIMIT=55555

# Get the current limit for the number of open files
current_limit=$(ulimit -n)

if [ "$current_limit" -lt "$MIN_LIMIT" -a "$CHECK_LIMITS" -eq 1 ]; then
  echo "Error: The current limit for the number of open files is too low ($current_limit)."
  echo "Please increase the limit to at least $MIN_LIMIT by running the following command:"
  echo "ulimit -n $MIN_LIMIT"
  echo "Note: This change will only apply to the current shell session."
  exit 1
fi

# Set a minimum required limit for max map count
MIN_MAP_COUNT=2621440

# Get the current value for vm.max_map_count
current_map_count=$(sysctl -n vm.max_map_count)

if [ "$current_map_count" -lt "$MIN_MAP_COUNT" -a "$CHECK_LIMITS" -eq 1 ]; then
  echo "Error: The current value for vm.max_map_count is too low ($current_map_count)."
  echo "Please increase the value to at least $MIN_MAP_COUNT by running the following command:"
  echo "sudo sysctl -w vm.max_map_count=$MIN_MAP_COUNT"
  echo "To make the change permanent, add the following line to /etc/sysctl.conf:"
  echo "vm.max_map_count=$MIN_MAP_COUNT"
  exit 1
fi

if [ -z "${DEMOSRC}" ]; then
    echo "Using default demo..."

    # Ensure the datadir files are downloaded. This is 600 json files to parse.
    if ! [ -f ./elm/tag-site-demo/datadir.tar.gz ]; then
        pushd ./elm/tag-site-demo
        wget -O datadir.tar.gz \
             https://www.dropbox.com/s/a9dwuiny135pk6o/datadir.tar.gz?dl=1
        mkdir -p datadir/json/
        # previous demo was just json, now requires json/img separation in the
        # big demo.
        tar xf datadir.tar.gz -C datadir/json --strip-components=1
        popd
    fi

    DEMOSRC="./elm/tag-site-demo/datadir"
fi

if [ "${REQ_LAST_PAGE}" -ne 0 ]; then
    LAST_PAGE=$REQ_LAST_PAGE
else
    LAST_PAGE=$(ls "${DEMOSRC}/json" | grep -o -E '[0-9]+' | sort -n | tail -n 1)
fi

UPLOAD_IMG=0

if [ "${USE_LOCAL}" -eq 1 -a "${USE_CDN}" -eq 1 ]; then
    echo "Error: Can't both set --use-local and --use-cdn"
    exit 2
elif [ "${USE_LOCAL}" -eq 1 ]; then
    if [ -d "$DEMOSRC/img/" ]; then
        UPLOAD_IMG=1
    else
        echo "Error: Can't --use-local on a dataset without images"
        exit 2
    fi
fi

rm -Rf "$MACHINE_DIR"
mkdir -p "$MACHINE_DIR"

# Ensure the elm files are built.
if ! [ -f ./elm/tag-site-demo/elm.js ]; then
    nix-shell -p elmPackages.elm --run "cd ./elm/tag-site-demo && sh/build"
elif [ ./elm/tag-site-demo/src/Main.elm -nt ./elm/tag-site-demo/elm.js ]; then
    nix-shell -p elmPackages.elm --run "cd ./elm/tag-site-demo && sh/build"
fi

waited=0
until [ -d "$MACHINE_DIR" ]
do
    if [ $waited -eq 0 ]; then
        echo "Waiting for $MACHINE_DIR directory to be created"
        waited=1
    fi

    sleep 0.1
done

# TODO: error out if this broke.
pallas boot "$MACHINE_DIR" sire/demo_full_tag_site.sire

pallas start "${MACHINE_ARGS[@]}" "$MACHINE_DIR" &
RUN_MACHINE=$!

echo "started..."

until find "$MACHINE_DIR" -maxdepth 1 -name "tcp.port" -quit
do
     echo "Waiting..."
     sleep 0.1
done

# Why an additional sleep here? Some weird filesystem sync issue where the
# port file was created, but hasn't been written to yet.
sleep 0.1

PORT=$(cat "$MACHINE_DIR"/tcp.port)

echo "Setting interface files..."
curl --http1.0 --data-binary @./elm/tag-site-demo/elm.js -H "Content-Type: text/javascript" -H "X-Put-Path: /elm.js" -X POST http://localhost:$PORT/put
curl --http1.0 --data-binary @./elm/tag-site-demo/index-xmlhttprequest.html -H "Content-Type: text/html" -H "X-Put-Path: /index.html" -X POST http://localhost:$PORT/put

echo "Interface files are set. Running on http://localhost:$PORT/index.html"

if [ ${UPLOAD_IMG} -eq 1 ]; then
    echo "Setting use local images only..."
    curl --http1.0 -X POST "http://localhost:$PORT/uselocal"
fi

echo "Sending JSON dumps..."

upload_images_for_file () {

    if [ ${UPLOAD_IMG} -ne 1 ]; then
        return
    fi

    echo "page-$i.json (IMG)"

    local FILE="$1"

    local CURL_ARGS=""

    # Get all the thumbnail URLs from the file.
    local urls=$(cat $FILE | jq -r ".images[] | .representations.thumb")

    local url
    for url in $urls; do
        local BASEURL=$(dirname $url)
        local THUMBFILE=$(basename $url)
        local ID=$(basename $BASEURL)

        # Filesystems REALLY don't like directories with hundreds of thousands
        # of files, so on disk we have a two level structure where we cap
        # things at, ie, for an $ID of 1522818, the file is at
        # `1520000/1522818/thumb.gif`.
        if [ $ID -lt "10000" ]
        then BASEDIR="0"
        else BASEDIR="$(expr $ID / 10000)0000"
        fi

        # Check file existence to work around derpicdn not always agreeing with
        # the database.
        local THUMBSRC="$DEMOSRC/img/$BASEDIR/$ID/$THUMBFILE"
        local THUMBDST="http://localhost:$PORT/img/$ID/$THUMBFILE"
        if [ -f "$THUMBSRC" ]; then
            CURL_ARGS+="-T $THUMBSRC $THUMBDST "
        fi
    done

    # Upload files 50 at a time so we get some http connection reusage.
    curl --http1.0 $CURL_ARGS

    # If we error, we have to hard stop this thread because otherwise we're
    # going to spam the console to the point where noone can see what happened.
    if [[ $? != 0 ]]; then
        exit -1
    fi
}

#
# Each thread takes a slice of the page-space.
#
# For example, if there are four threads, the distribution will be:
#
# thread 0: 0 4  8 12 16 ...
# thread 1: 1 5  9 13 17 ...
# thread 2: 2 6 10 14 18 ...
# thread 3: 3 7 11 15 19 ...
#
upload_pages () {
    local threadnum=$1
    local top=$(($FIRST_PAGE + $threadnum))

    local i
    for i in $(seq $top $THREADS $LAST_PAGE); do
        local FILE="$DEMOSRC/json/page-$i.json"
        local url="http://localhost:$PORT/learn";
        if [ -e "$FILE" ]
        then
            upload_images_for_file "$FILE"

            echo "page-$i.json"
            curl --http1.0 -d @$FILE -H "Content-Type: application/json" -X POST "$url"
            if [[ $? != 0 ]]; then
                exit -1
            fi
        fi
    done
}

last_thread=$(($THREADS - 1))

for i in $(seq 0 $last_thread); do
    upload_pages $i &
    tid[$i]=$!;
done

cleanup () {
    for i in $(seq 0 $last_thread); do
        kill ${tid[$i]} 2>/dev/null
    done
}

trap cleanup EXIT

for i in $(seq 0 $last_thread); do
    wait ${tid[$i]}
done

echo "Running on http://localhost:$PORT/index.html"

if [ $RUN_TESTS -eq 1 ]
then
    json='{"tag":"Search","contents":{"offset":0,"tags":["cute"]}}'

    sleep 0.5

    curl --http1.0 -XPOST http://localhost:$PORT/search -d "$json" >out.json

    cleanup () { rm -f out.json; rm -r "$MACHINE_DIR"; }
    trap cleanup EXIT

    failed=0

    fail () {
        "TESTS FAILED: json output does not match expectations"
        jq . < out.json
        failed=1
    }

    test 500 -eq $(jq .status.imgs out.json)    || fail
    test 377 -eq $(jq .contents.total out.json) || fail

    if [ $failed = 0 ]; then
        echo "TEST SUCCESS: demo_full_tag_site"
    fi

    kill $RUN_MACHINE
    wait $RUN_MACHINE
    exit
fi

wait $RUN_MACHINE
